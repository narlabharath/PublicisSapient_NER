{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff7a85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Sample Sentence: tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 12, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])\n",
      "Sample Sentence Shape: torch.Size([1, 31])\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import joblib\n",
    "import yaml\n",
    "import os\n",
    "from src.models.bilstm_crf_model import BiLSTM_CRF\n",
    "\n",
    "# Load configuration\n",
    "config_path = 'config/bilstm_crf_config.yaml'\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Load the trained model\n",
    "vocab_size = 10000  # Adjust based on your actual vocab size\n",
    "tagset_size = 18    # Adjust based on your actual tag size\n",
    "\n",
    "model = BiLSTM_CRF(vocab_size, tagset_size, config['model']['embedding_dim'], config['model']['hidden_dim'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Load a small batch of data\n",
    "data_path = 'data/processed/bilstm_train.pkl'\n",
    "X, y = joblib.load(data_path)\n",
    "\n",
    "# Take a small sample sentence\n",
    "sent = torch.tensor(X[0], dtype=torch.long).unsqueeze(0)  # Batch size 1\n",
    "print(\"Sample Sentence:\", sent)\n",
    "print(\"Sample Sentence Shape:\", sent.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6449eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence (Batch First): tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 12, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])\n",
      "Input Shape: torch.Size([1, 31])\n"
     ]
    }
   ],
   "source": [
    "# Check input dimensions\n",
    "print(\"Input Sentence (Batch First):\", sent)\n",
    "print(\"Input Shape:\", sent.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899b5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Output Shape: torch.Size([1, 31, 100])\n",
      "Embedding Output (First 5 Tokens): tensor([[ 4.3985e-01, -1.6485e+00, -8.8791e-01,  7.1116e-01,  4.6108e-02,\n",
      "         -5.5073e-01, -5.6396e-01,  1.8835e+00,  9.9901e-01,  7.9519e-01,\n",
      "          1.2114e+00,  5.0557e-01, -8.4548e-01, -1.4257e+00,  3.0945e-01,\n",
      "          1.6079e-01,  2.0867e-01, -2.5437e-01, -4.2353e-02,  8.7499e-02,\n",
      "          3.8745e-01, -9.9284e-01, -1.7035e+00,  7.5859e-01,  8.5649e-01,\n",
      "         -3.1103e-01, -1.4060e+00,  1.5158e+00, -8.5780e-01,  7.0593e-01,\n",
      "          5.4726e-01,  1.6098e+00, -4.8729e-02,  3.9417e-01, -1.4241e-01,\n",
      "          1.0993e+00, -6.5213e-01,  3.0283e-01, -8.7332e-01, -7.2792e-01,\n",
      "          9.0189e-01,  2.2705e+00, -1.4012e+00,  1.0091e-01,  2.5080e-01,\n",
      "          1.1738e+00,  5.3529e-01,  2.8089e-01,  5.6923e-01, -8.6394e-01,\n",
      "         -1.4258e+00,  1.8027e+00,  6.5605e-01, -2.2597e+00, -5.5891e-02,\n",
      "          1.3291e+00,  5.0488e-01,  7.1280e-01,  1.9835e+00, -1.4426e+00,\n",
      "         -8.7028e-01, -1.5301e-02, -1.1505e+00,  8.8465e-01,  6.0676e-01,\n",
      "         -1.3514e+00,  1.5993e-01,  2.8772e+00,  2.9448e-01, -1.8775e-01,\n",
      "          1.1991e+00, -5.4309e-01,  3.7178e-01,  2.6161e-01, -1.1902e+00,\n",
      "          8.0652e-01,  6.5124e-01, -1.3854e+00, -1.1832e+00,  2.6438e+00,\n",
      "          2.6304e-01, -3.0763e-01, -2.4740e-01, -1.3934e+00, -5.5154e-01,\n",
      "          4.0068e-01, -1.3073e-01,  9.8226e-01,  6.2585e-01, -4.3478e-01,\n",
      "         -9.9817e-01, -4.9710e-01, -3.3396e-01,  6.2866e-01, -4.1924e-01,\n",
      "         -9.6491e-01,  1.6597e-01, -5.6430e-01, -1.0725e+00, -2.9930e-01],\n",
      "        [-4.0090e-01,  8.6731e-01,  1.1742e+00, -2.7534e-03,  3.0072e-01,\n",
      "          4.4212e-01,  1.3816e+00,  6.3928e-01, -9.2051e-01,  9.1049e-01,\n",
      "          7.0682e-01, -8.2697e-01, -5.5269e-01,  5.0859e-01,  7.1349e-01,\n",
      "          4.3093e-01,  2.0454e-01, -3.4152e-01,  5.7834e-01, -1.1944e-01,\n",
      "          1.4547e+00, -3.1999e-02,  6.8425e-01,  1.5384e-01, -2.0332e-01,\n",
      "          1.3293e+00, -5.8922e-02,  4.5936e-01,  2.3083e+00, -9.3292e-01,\n",
      "          2.2807e+00, -6.6624e-01,  1.2267e+00, -8.1219e-01, -6.8206e-01,\n",
      "          3.9606e-01,  2.5733e+00, -5.3947e-01,  1.8953e-01,  1.3346e+00,\n",
      "         -1.0028e+00,  1.0988e+00,  1.0739e+00, -8.0272e-01,  7.8369e-01,\n",
      "          3.4148e-03, -1.6147e-01,  4.3351e-01,  4.0810e-01, -1.2970e+00,\n",
      "          2.5447e+00, -1.9556e-03, -8.3685e-01, -1.5046e+00, -2.0456e-01,\n",
      "          1.0411e-01, -5.2486e-01, -1.3008e+00, -1.7824e+00,  2.2963e-01,\n",
      "          9.0586e-01,  1.1152e-01, -7.0349e-01, -1.9242e+00,  9.1138e-01,\n",
      "         -4.4663e-01,  1.2336e+00,  5.1748e-01,  1.5409e+00,  8.1619e-01,\n",
      "         -9.2234e-01,  6.6670e-01, -2.9171e-01,  8.5249e-01, -9.7753e-01,\n",
      "          4.1417e-02, -2.1451e-01,  4.2238e-01, -6.7750e-01,  2.4766e-01,\n",
      "          6.2243e-01, -9.1890e-01,  7.0875e-01, -6.1449e-01, -1.3103e+00,\n",
      "         -7.9938e-01, -2.2326e-01, -5.8600e-01,  3.5650e-01, -1.1948e+00,\n",
      "          1.6678e+00,  3.8268e-03,  1.1550e-02,  1.1877e+00,  1.2283e+00,\n",
      "         -3.4282e-01, -1.6285e+00,  5.0289e-01,  1.7832e-01, -1.0517e-01],\n",
      "        [-2.1098e-01, -1.7361e-01,  1.3345e+00, -1.0382e+00,  6.6260e-01,\n",
      "          1.5256e+00,  4.5333e-01, -9.8384e-01, -7.4051e-01,  3.6244e-01,\n",
      "         -8.7223e-01, -6.8864e-01, -7.0429e-01,  3.4517e-01,  7.6838e-01,\n",
      "          7.6157e-01, -1.2925e+00,  1.0405e-01,  9.7612e-01, -6.5540e-01,\n",
      "         -1.7968e+00,  3.2397e-01, -7.1572e-01, -8.9301e-01, -1.1600e+00,\n",
      "         -6.2773e-01, -2.2778e+00, -1.2573e+00,  5.8786e-02, -6.6272e-01,\n",
      "          4.9010e-01,  7.6536e-01,  1.3288e+00, -7.8802e-02, -1.4869e+00,\n",
      "          1.0174e+00, -1.6150e-01,  1.9828e+00, -1.2207e+00, -2.1932e+00,\n",
      "         -1.0484e+00, -4.5446e-02,  8.4019e-01, -8.1948e-01, -1.0983e+00,\n",
      "         -1.4900e+00, -9.1823e-01,  4.5865e-01, -4.4204e-01,  6.5852e-01,\n",
      "         -3.3640e-01, -1.9123e+00,  1.0425e+00,  5.9606e-01, -6.7065e-01,\n",
      "         -8.9029e-01, -2.2933e-01, -1.8577e+00,  8.5244e-01,  1.3815e-01,\n",
      "          6.9662e-01,  5.1831e-01, -1.6654e-01,  3.6197e-01, -3.6203e-01,\n",
      "         -2.3031e-01,  2.2652e+00, -9.9258e-01,  1.9733e+00,  4.1018e-01,\n",
      "          1.0228e+00,  2.7261e-01,  5.8722e-01, -2.5221e-01, -4.0645e-01,\n",
      "         -1.5668e-01, -7.5350e-01, -6.0011e-01, -4.7729e-01, -2.5111e-01,\n",
      "         -4.1803e-02,  1.3544e+00, -4.3241e-01,  5.3594e-02,  4.5753e-01,\n",
      "         -1.0134e+00, -3.6556e-01, -6.1039e-02, -8.5848e-01,  3.3443e-01,\n",
      "         -9.5253e-01, -5.5441e-01,  3.0912e-01, -3.8002e-01,  3.9215e-01,\n",
      "          3.8818e-01,  1.5049e+00, -1.1139e+00, -8.6668e-01, -3.0120e-01],\n",
      "        [-7.2019e-01,  1.2094e+00, -3.0268e+00,  2.5485e+00,  1.7031e-01,\n",
      "         -1.5803e+00,  3.3614e-01,  5.9715e-01, -1.6919e+00, -2.4148e+00,\n",
      "         -1.0429e+00,  5.4302e-01,  2.6373e-02, -7.9276e-01, -1.0762e+00,\n",
      "         -7.6741e-01,  2.6964e-01, -7.7164e-01,  4.4021e-01, -1.3434e+00,\n",
      "         -8.4120e-01,  9.3247e-02, -2.7392e-01, -1.2984e+00,  5.4223e-01,\n",
      "          6.1492e-01, -2.4744e-01, -8.8424e-01, -2.6561e-01,  1.1311e+00,\n",
      "          6.0407e-02,  2.3343e-01, -1.4192e+00,  1.5258e+00, -2.3314e-01,\n",
      "          1.6869e+00,  7.7054e-01, -4.3616e-01,  2.7963e-01, -3.9006e-01,\n",
      "         -2.8680e-01, -6.1649e-01,  1.4769e-01, -1.7965e+00, -4.8197e-01,\n",
      "         -5.9343e-01, -2.5732e-01,  6.1798e-01,  2.0196e+00, -1.8327e+00,\n",
      "          5.5862e-01, -1.0208e+00, -6.9841e-01, -3.9173e-02, -9.4825e-02,\n",
      "         -2.1314e+00, -6.4029e-01,  2.0496e+00, -1.0263e+00,  1.0877e-01,\n",
      "         -1.5625e+00, -1.7705e+00,  3.8853e-01, -1.7313e+00,  1.3323e+00,\n",
      "         -1.5982e+00, -1.1822e+00,  1.2198e-01,  1.2769e+00,  3.1010e-01,\n",
      "         -6.0490e-02, -8.4675e-03, -2.2649e-01,  1.1227e+00, -1.5301e+00,\n",
      "         -4.7134e-02, -1.4645e+00,  1.2865e+00,  8.4201e-01,  5.2872e-01,\n",
      "         -5.2120e-01, -4.8103e-01, -2.4348e+00, -2.7461e-01,  9.3630e-01,\n",
      "          2.8247e-01,  1.1412e+00,  2.0798e-01,  1.2276e+00, -6.0458e-01,\n",
      "         -6.4869e-01, -8.2557e-01,  1.0183e+00, -2.5395e-01,  1.5575e+00,\n",
      "         -9.3206e-01,  6.8640e-01, -3.4796e-01, -1.9340e-01,  4.1294e-01],\n",
      "        [-8.8607e-01,  8.9812e-01,  3.7425e-01,  9.5021e-01, -9.4362e-01,\n",
      "          1.1744e+00,  6.9000e-01, -1.3265e-01, -1.9734e-01,  5.0987e-01,\n",
      "          8.6703e-01,  1.1988e+00,  2.3196e+00, -1.4570e-01,  1.8257e-01,\n",
      "         -2.6996e-01,  1.1097e+00,  6.0104e-01,  1.1816e-01, -4.0234e-01,\n",
      "         -1.3214e+00,  5.3791e-01,  7.1970e-01, -8.0123e-01, -1.5280e+00,\n",
      "          1.4070e-01, -9.8542e-01,  1.8138e-01,  3.1686e-01, -1.2873e+00,\n",
      "         -9.7399e-01,  1.2699e+00,  1.1989e-01, -1.0926e+00, -1.1324e+00,\n",
      "          7.2446e-01, -1.7046e-01, -6.4148e-01,  5.3012e-01,  6.1611e-01,\n",
      "         -6.3694e-01,  2.1655e+00,  1.0375e+00, -4.2386e-01,  1.3891e+00,\n",
      "          3.1612e+00, -6.7292e-01, -7.2159e-01,  7.9287e-01, -8.8256e-01,\n",
      "         -1.2861e+00, -4.3702e-01, -4.9839e-01, -4.5645e-02,  2.0603e-01,\n",
      "          1.9283e+00, -1.1321e-01,  1.2473e-01,  6.1027e-01, -9.6988e-01,\n",
      "          3.6173e-01, -1.2948e+00, -3.5597e-02, -6.1703e-01,  3.5178e-01,\n",
      "          1.2144e+00,  6.4095e-01,  8.5589e-01,  8.5014e-01, -2.2989e-01,\n",
      "         -3.9479e-01, -6.6781e-01, -3.1645e-01, -2.1333e-01,  1.6041e+00,\n",
      "          1.1077e+00, -1.3504e+00,  9.3048e-02, -1.2161e+00,  1.0797e+00,\n",
      "         -9.1402e-01,  2.1772e-01, -1.3178e+00, -5.8121e-01, -3.5056e-01,\n",
      "          1.1293e-01,  1.0436e+00,  1.8856e-01,  2.2230e+00,  2.1001e+00,\n",
      "         -5.8932e-01, -3.2258e-01,  8.7355e-01,  1.6068e+00, -5.0067e-01,\n",
      "         -1.3703e+00, -4.8983e-02,  6.4933e-01, -1.8538e-01, -1.9884e-01]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embeds = model.word_embeds(sent)\n",
    "    print(\"Embedding Output Shape:\", embeds.shape)\n",
    "    print(\"Embedding Output (First 5 Tokens):\", embeds[0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469d6f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Output Shape: torch.Size([1, 31, 256])\n",
      "LSTM Output (First 5 Steps): tensor([[ 0.0250,  0.0636,  0.0290,  ..., -0.0281, -0.0535, -0.0312],\n",
      "        [ 0.0115,  0.1023, -0.0111,  ..., -0.0363, -0.0654, -0.0264],\n",
      "        [ 0.0255,  0.0957, -0.0360,  ..., -0.0329, -0.0690, -0.0196],\n",
      "        [ 0.0453,  0.1414, -0.0528,  ..., -0.0706, -0.0470,  0.0163],\n",
      "        [ 0.0634,  0.1432, -0.0053,  ..., -0.0705, -0.0318,  0.0138]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    lstm_out, _ = model.lstm(embeds)\n",
    "    print(\"LSTM Output Shape:\", lstm_out.shape)\n",
    "    print(\"LSTM Output (First 5 Steps):\", lstm_out[0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed32f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Features (Emission Scores) Shape: torch.Size([1, 31, 18])\n",
      "Emission Scores (First 5 Steps): tensor([[-0.0495,  0.0672,  0.0499,  0.0187, -0.0161, -0.0563, -0.0086,  0.0611,\n",
      "          0.0098, -0.0463, -0.0643, -0.0516, -0.0005,  0.0629, -0.0445,  0.0563,\n",
      "          0.0398, -0.0306],\n",
      "        [-0.0445,  0.0721,  0.0708,  0.0387, -0.0183, -0.0586, -0.0289,  0.0714,\n",
      "          0.0216, -0.0461, -0.0523, -0.0450, -0.0090,  0.0646, -0.0499,  0.0555,\n",
      "          0.0324, -0.0260],\n",
      "        [-0.0516,  0.0409,  0.0768,  0.0558, -0.0067, -0.0431, -0.0306,  0.0650,\n",
      "          0.0266, -0.0449, -0.0424, -0.0324, -0.0041,  0.0634, -0.0448,  0.0627,\n",
      "          0.0333, -0.0157],\n",
      "        [-0.0694,  0.0413,  0.0526,  0.0414,  0.0116, -0.0535, -0.0031,  0.0542,\n",
      "          0.0328, -0.0594, -0.0390, -0.0342, -0.0028,  0.0564, -0.0555,  0.0886,\n",
      "          0.0384,  0.0009],\n",
      "        [-0.0706,  0.0556,  0.0507,  0.0097,  0.0134, -0.0671, -0.0010,  0.0614,\n",
      "          0.0459, -0.0553, -0.0510, -0.0412,  0.0107,  0.0589, -0.0676,  0.0873,\n",
      "          0.0635, -0.0177]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    lstm_feats = model.hidden2tag(lstm_out)\n",
    "    print(\"LSTM Features (Emission Scores) Shape:\", lstm_feats.shape)\n",
    "    print(\"Emission Scores (First 5 Steps):\", lstm_feats[0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eb84087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viterbi Decoding Score: tensor([-19906.9805], grad_fn=<IndexBackward0>)\n",
      "Predicted Tag Sequence: [[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    score, tag_seq = model._viterbi_decode(lstm_feats)\n",
    "    print(\"Viterbi Decoding Score:\", score)\n",
    "    print(\"Predicted Tag Sequence:\", tag_seq)\n",
    "except Exception as e:\n",
    "    print(\"Error during Viterbi Decoding:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7e81d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix:\n",
      "Parameter containing:\n",
      "tensor([[-1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "         -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "         -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
      "         -1.0000e+04, -1.0000e+04, -1.0000e+04],\n",
      "        [-1.0000e+04, -1.6847e+00, -1.4650e+00,  3.8129e-01, -8.0737e-03,\n",
      "          2.0782e+00,  1.0535e-02, -3.5243e-01,  4.2435e-01,  8.4695e-01,\n",
      "         -1.1362e-01,  4.5446e-01, -1.0574e+00,  9.4980e-01,  9.9600e-01,\n",
      "         -3.2728e-01, -3.5063e-01,  5.1021e-01],\n",
      "        [-1.0000e+04, -1.7474e+00, -5.0859e-02, -9.2646e-01,  1.0532e+00,\n",
      "         -7.9413e-02,  7.8410e-02, -2.6374e-01, -6.8105e-02,  1.2402e+00,\n",
      "         -2.7998e-02, -1.0916e+00, -2.3756e-01,  2.6666e-01, -9.6932e-01,\n",
      "          5.5455e-02, -8.6848e-01, -2.5927e-01],\n",
      "        [-1.0000e+04, -1.8121e-02, -1.4713e+00, -1.6999e+00, -8.7816e-01,\n",
      "          1.8334e-01, -7.9039e-01, -1.8654e+00,  7.5694e-01, -1.0451e+00,\n",
      "          1.0273e+00,  1.1376e+00,  9.7794e-01,  2.6599e-01, -1.2986e-01,\n",
      "         -6.2565e-01,  7.7272e-01, -1.4078e-01],\n",
      "        [-1.0000e+04,  5.5106e-01, -4.5041e-01,  7.9253e-02,  4.2994e-01,\n",
      "          1.2880e+00,  9.6625e-01, -4.0414e-01,  7.3966e-01, -6.7407e-01,\n",
      "         -1.4354e+00,  2.0987e-01,  5.8569e-01, -9.3066e-01,  4.7353e-01,\n",
      "          9.4558e-01,  1.2438e+00, -9.4106e-01],\n",
      "        [-1.0000e+04,  3.0530e-01, -1.7990e+00,  7.6063e-01,  5.4471e-01,\n",
      "         -2.8621e-01,  6.2434e-01,  6.2207e-01, -1.0541e+00,  6.8037e-01,\n",
      "          7.4162e-01,  1.9161e+00,  2.2841e-02, -6.7223e-01, -1.8508e+00,\n",
      "         -4.4836e-01, -1.0136e+00,  8.5005e-01],\n",
      "        [-1.0000e+04, -9.5255e-01, -4.0599e-01,  1.2205e+00,  1.2457e+00,\n",
      "          1.5460e+00,  8.9604e-01, -1.5405e+00,  1.9591e+00,  1.6099e+00,\n",
      "         -1.0796e+00,  3.5810e-01,  5.0651e-01, -1.1444e+00,  1.4818e+00,\n",
      "         -5.7754e-01, -8.4226e-01,  1.9009e-01],\n",
      "        [-1.0000e+04,  2.9025e-02, -8.5448e-01, -5.2341e-01,  5.4676e-01,\n",
      "         -4.2256e-02,  2.7697e-01, -1.6029e+00, -3.1824e-01, -1.8174e+00,\n",
      "         -1.8511e+00,  1.2549e-01,  1.1401e-01,  1.1587e-01, -1.1396e+00,\n",
      "         -3.0175e-02, -3.3002e-01,  9.8136e-01],\n",
      "        [-1.0000e+04, -1.6356e+00,  9.3670e-01,  1.1365e-02,  1.2910e+00,\n",
      "          3.3620e-01, -7.4489e-01,  4.4316e-01,  1.4068e+00, -1.8310e+00,\n",
      "         -6.6068e-01,  6.2014e-01, -7.9991e-01,  1.4617e+00, -1.3060e+00,\n",
      "         -2.4187e-01, -1.0875e+00, -8.0407e-01],\n",
      "        [-1.0000e+04, -2.9750e-01, -2.5137e+00,  5.3148e-01,  6.5646e-01,\n",
      "          1.5359e-01, -1.0427e-01, -1.2231e-01, -9.8648e-01, -1.0117e-01,\n",
      "         -2.3965e-01,  1.0904e+00,  1.0045e-01, -1.1774e-02,  3.8080e-01,\n",
      "          1.7635e+00,  4.7290e-01, -1.0472e+00],\n",
      "        [-1.0000e+04, -2.4874e-01,  1.8552e+00, -2.3023e-01,  1.2955e+00,\n",
      "         -2.4404e+00, -1.4171e+00, -7.9311e-01,  1.3218e+00, -2.7800e-01,\n",
      "          8.5371e-01,  1.6573e+00,  3.0111e-01,  1.1662e+00,  9.1654e-01,\n",
      "         -3.3706e-01, -7.8650e-01, -1.2645e+00],\n",
      "        [-1.0000e+04,  7.1994e-01,  6.1939e-01, -2.5311e-01, -7.1140e-01,\n",
      "         -2.3714e+00,  7.8776e-01, -1.9467e-01, -1.4041e+00, -5.9331e-01,\n",
      "         -1.4789e+00, -1.9684e+00, -5.3169e-01,  2.9212e-01, -1.0545e+00,\n",
      "          6.2979e-01,  3.1446e-02, -1.7145e-01],\n",
      "        [-1.0000e+04,  1.4799e+00, -6.8369e-01, -3.7366e-01, -1.8650e-01,\n",
      "         -5.6277e-02,  1.2691e+00,  6.4118e-02,  1.0996e+00,  1.9239e+00,\n",
      "         -3.6543e-01, -6.6499e-01,  2.9938e+00, -4.9023e-01,  2.4204e-01,\n",
      "          8.8200e-01, -6.5415e-01, -7.4548e-04],\n",
      "        [-1.0000e+04,  9.9625e-01,  4.0809e-01, -5.2098e-01, -3.2330e-02,\n",
      "          8.7128e-01, -5.4499e-01,  3.9165e-01, -9.2338e-02, -2.3106e-01,\n",
      "          3.5266e-01, -1.0108e+00,  7.2851e-01, -1.0327e+00, -3.4403e-01,\n",
      "         -6.1220e-01,  2.9660e+00,  1.1075e+00],\n",
      "        [-1.0000e+04, -1.4714e-01, -8.6618e-02, -2.1964e-02,  4.5399e-02,\n",
      "         -1.5977e+00, -7.3496e-01, -8.8793e-01,  9.3566e-02,  8.9206e-01,\n",
      "         -5.5327e-01,  8.1027e-01, -7.9597e-01, -3.1135e-01,  1.3198e-01,\n",
      "         -1.2416e+00, -6.0509e-01,  1.0844e+00],\n",
      "        [-1.0000e+04, -8.8857e-01,  1.0859e-01,  1.7576e+00, -4.0268e-02,\n",
      "         -1.2443e+00,  8.7002e-01,  2.3431e-01,  4.1420e-01, -1.4049e+00,\n",
      "          3.9929e-02, -4.1374e-02,  9.6062e-01,  7.8362e-01, -1.8889e+00,\n",
      "          1.6271e+00, -6.2257e-01,  1.5999e+00],\n",
      "        [-1.0000e+04,  3.2861e-01,  9.9898e-01,  8.7373e-01, -4.9883e-01,\n",
      "         -5.0112e-01, -6.2721e-01, -1.2435e+00, -1.7652e-01,  2.9308e-01,\n",
      "          2.5521e-01, -1.3910e+00, -8.6168e-01, -1.7604e+00,  5.4047e-02,\n",
      "         -2.1104e-01,  1.3574e+00, -7.5154e-01],\n",
      "        [-1.0000e+04,  7.6362e-03, -5.8875e-02,  1.7817e+00, -1.3984e+00,\n",
      "         -9.9774e-01,  4.2664e-01, -9.8968e-01,  8.2239e-01,  1.0348e+00,\n",
      "          8.3718e-01,  5.2929e-01, -9.2076e-01, -6.9252e-01,  1.0420e+00,\n",
      "         -5.8421e-01,  2.3876e-01,  1.3246e+00]], requires_grad=True)\n",
      "Transition Matrix Shape: torch.Size([18, 18])\n",
      "Max Transition Value: 2.9938080310821533, Min Transition Value: -10000.0\n"
     ]
    }
   ],
   "source": [
    "# Check the transition matrix values\n",
    "print(\"Transition Matrix:\")\n",
    "print(model.transitions)\n",
    "print(\"Transition Matrix Shape:\", model.transitions.shape)\n",
    "\n",
    "# Check for any dominant values (indicative of initialization issues)\n",
    "max_val = torch.max(model.transitions)\n",
    "min_val = torch.min(model.transitions)\n",
    "print(f\"Max Transition Value: {max_val.item()}, Min Transition Value: {min_val.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c0796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Log-Likelihood Loss: -9889.203125\n"
     ]
    }
   ],
   "source": [
    "# Create a sample tag tensor for testing the loss calculation\n",
    "tags = torch.tensor(y[0], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "# Calculate the negative log-likelihood loss\n",
    "try:\n",
    "    loss = model.neg_log_likelihood(sent, tags)\n",
    "    print(\"Negative Log-Likelihood Loss:\", loss.item())\n",
    "except Exception as e:\n",
    "    print(\"Error during NLL calculation:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483d08c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Forward Pass - Viterbi Decoding Score: tensor([-19906.9805], grad_fn=<IndexBackward0>)\n",
      "Predicted Tag Sequence from Forward Pass: [[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]]\n"
     ]
    }
   ],
   "source": [
    "# Run a full forward pass to get the score and predicted tag sequence\n",
    "try:\n",
    "    score, tag_seq = model.forward(sent)\n",
    "    print(\"Full Forward Pass - Viterbi Decoding Score:\", score)\n",
    "    print(\"Predicted Tag Sequence from Forward Pass:\", tag_seq)\n",
    "except Exception as e:\n",
    "    print(\"Error during Full Forward Pass:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9291f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: -9889.203125\n",
      "Loss after one training step: -9892.375\n",
      "Loss decreased: True\n"
     ]
    }
   ],
   "source": [
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Define a simple optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Perform one training step\n",
    "try:\n",
    "    optimizer.zero_grad()\n",
    "    loss = model.neg_log_likelihood(sent, tags)\n",
    "    print(\"Initial Loss:\", loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Check loss after one step\n",
    "    loss_after = model.neg_log_likelihood(sent, tags)\n",
    "    print(\"Loss after one training step:\", loss_after.item())\n",
    "    print(\"Loss decreased:\", loss_after.item() < loss.item())\n",
    "except Exception as e:\n",
    "    print(\"Error during loss reduction check:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7d1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
